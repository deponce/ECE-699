{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, TensorDataset\n",
    "import torchattacks\n",
    "from torchsummary import summary\n",
    "from torchvision import models, datasets, transforms\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import sys\n",
    "from watermarkJPEG import *\n",
    "from JPEG_layer import * # some utils."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "        [\n",
    "            #transforms.Resize(256),\n",
    "            #transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "dataset = torchvision.datasets.ImageNet(root=\"./data/\", split='val',\n",
    "                             transform=transform\n",
    "                                       )\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Interpolate(nn.Module):\n",
    "    def __init__(self,size=(224,224), mode='bilinear') -> None:\n",
    "        super(Interpolate, self).__init__()\n",
    "        self.size = size\n",
    "        self.mode = mode\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        #input = torch.squeeze(input)\n",
    "        #return torch.unsqueeze(F.interpolate(input, size=self.size, mode=self.mode), dim=0)\n",
    "        return F.interpolate(input, size=self.size, mode=self.mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelIntegration(pretrained_model):\n",
    "    class IntegratedModel(nn.Module):\n",
    "        def __init__(self, pretrained_model):\n",
    "            super(IntegratedModel, self).__init__()\n",
    "            interpolate = Interpolate()\n",
    "            self.Integrated_Model = nn.Sequential(\n",
    "                interpolate,\n",
    "                pretrained_model\n",
    "            )\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.Integrated_Model(x)\n",
    "            return x\n",
    "    return IntegratedModel(pretrained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = models.resnet18(pretrained=True,  progress = True).to(device)\n",
    "#_ = pretrained_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "IntegratedModel = modelIntegration(pretrained_model).to(device)\n",
    "_=IntegratedModel.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recreate_image(im_as_var):\n",
    "    \"\"\"\n",
    "        Recreates images from a torch variable, sort of reverse preprocessing\n",
    "\n",
    "    Args:\n",
    "        im_as_var (torch variable): Image to recreate\n",
    "\n",
    "    returns:\n",
    "        recreated_im (numpy arr): Recreated image in array\n",
    "    \"\"\"\n",
    "    reverse_mean = [-0.485, -0.456, -0.406]\n",
    "    reverse_std = [1/0.229, 1/0.224, 1/0.225]\n",
    "    recreated_im = torch.clone(im_as_var)\n",
    "    recreated_im = recreated_im.cpu().numpy()[0]\n",
    "    for c in range(3):\n",
    "        recreated_im[c] /= reverse_std[c]\n",
    "        recreated_im[c] -= reverse_mean[c]\n",
    "    recreated_im[recreated_im > 1] = 1\n",
    "    recreated_im[recreated_im < 0] = 0\n",
    "    #recreated_im = np.round(recreated_im * 255)\n",
    "    recreated_im = recreated_im.transpose(1, 2, 0)\n",
    "    #recreated_im = np.uint8(recreated_im).transpose(1, 2, 0)\n",
    "    # Convert RBG to GBR\n",
    "    #recreated_im = recreated_im[..., ::-1]\n",
    "    return recreated_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recreate_image(im_as_var):\n",
    "    recreated_im = torch.clone(im_as_var)\n",
    "    recreated_im = recreated_im.cpu().numpy()[0]\n",
    "    #recreated_im = np.round(recreated_im * 255)\n",
    "    recreated_im = recreated_im.transpose(1, 2, 0)\n",
    "    #recreated_im = np.uint8(recreated_im).transpose(1, 2, 0)\n",
    "    # Convert RBG to GBR\n",
    "    #recreated_im = recreated_im[..., ::-1]\n",
    "    return recreated_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack = torchattacks.attacks.pgd.PGD(IntegratedModel,\n",
    "                                      eps=8/255,\n",
    "                                      alpha=1/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7fdff0264250>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50000 [00:00<?, ?it/s]/home/deponce/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:3609: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  warnings.warn(\n",
      "/home/deponce/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "100%|██████████| 50000/50000 [15:51:21<00:00,  1.14s/it]  \n"
     ]
    }
   ],
   "source": [
    "correct_cnt = 0\n",
    "block_cnt = 0\n",
    "cum_turb = np.zeros((8,8))\n",
    "for _ in tqdm((range(len(test_loader)))):\n",
    "    data, target = next(iter(test_loader))\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    #data.requires_grad = True\n",
    "    output = IntegratedModel(data)\n",
    "    init_pred = output.max(1, keepdim=True)[1]\n",
    "    attack_img = attack(data, init_pred[0])\n",
    "    # we assume that thh accuracy of the model is 1\n",
    "    turb_noise = (attack_img - data).cpu().numpy()[0].transpose(1, 2, 0)\n",
    "    #print(type(turb_noise),turb_noise.shape)\n",
    "    img_YUV = cv2.cvtColor(turb_noise, cv2.COLOR_BGR2YUV)*255\n",
    "    img_Y = img_YUV[:,:,0].copy()\n",
    "    block_index = -1\n",
    "    for i in range(0,int(np.floor(img_YUV.shape[0]/8)*8),8):\n",
    "        for j in range(0,int(np.floor(img_YUV.shape[1]/8)*8),8):\n",
    "            block_index += 1\n",
    "            current_block = img_Y[i:i+8,j:j+8]\n",
    "            block_dct = cv2.dct(current_block)\n",
    "            cum_turb += np.abs(block_dct)\n",
    "            block_cnt +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimg_re = recreate_image(attack_img.detach())\\n#print(torch.max(img_re))\\nprint(torch.sum(attack_img-data))\\nprint(init_pred,\"-->\",target)\\nprint(\"#--------------------------------#\")\\nprint(\"orig\")\\nplt.imshow(recreate_image(data.detach()), interpolation=\\'none\\')\\nplt.xticks([])\\nplt.yticks([])\\nplt.show()\\nprint(\"v\")\\nprint(\"|\")\\nprint(\"v\")\\nprint(\"noisy\")\\nplt.imshow(img_re, interpolation=\\'none\\')\\nplt.xticks([])\\nplt.yticks([])\\nplt.show()\\nprint(\"#--------------------------------#\")\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    \"\"\"\n",
    "    img_re = recreate_image(attack_img.detach())\n",
    "    #print(torch.max(img_re))\n",
    "    print(torch.sum(attack_img-data))\n",
    "    print(init_pred,\"-->\",target)\n",
    "    print(\"#--------------------------------#\")\n",
    "    print(\"orig\")\n",
    "    plt.imshow(recreate_image(data.detach()), interpolation='none')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()\n",
    "    print(\"v\")\n",
    "    print(\"|\")\n",
    "    print(\"v\")\n",
    "    print(\"noisy\")\n",
    "    plt.imshow(img_re, interpolation='none')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()\n",
    "    print(\"#--------------------------------#\")\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/deponce/ECE699'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179216434"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.58489075e+09, 1.10609953e+09, 9.55979093e+08, 7.87738279e+08,\n",
       "        6.54474643e+08, 6.07578847e+08, 5.18174214e+08, 4.06497216e+08],\n",
       "       [1.13166132e+09, 9.72885545e+08, 8.56975178e+08, 7.17166788e+08,\n",
       "        6.01022010e+08, 5.55717840e+08, 4.73239469e+08, 3.77744007e+08],\n",
       "       [9.80189560e+08, 8.72715544e+08, 7.70449479e+08, 6.46776977e+08,\n",
       "        5.47900180e+08, 5.08917178e+08, 4.39761886e+08, 3.60948821e+08],\n",
       "       [8.17493728e+08, 7.42801160e+08, 6.56981810e+08, 5.51158415e+08,\n",
       "        4.77151132e+08, 4.50386912e+08, 3.99251676e+08, 3.41682253e+08],\n",
       "       [6.59811478e+08, 6.14297205e+08, 5.47841972e+08, 4.70519627e+08,\n",
       "        4.18888762e+08, 3.98790572e+08, 3.64427124e+08, 3.25322782e+08],\n",
       "       [5.78814667e+08, 5.43329292e+08, 4.89483029e+08, 4.30282225e+08,\n",
       "        3.89501514e+08, 3.70492958e+08, 3.44795328e+08, 3.16170288e+08],\n",
       "       [5.18017447e+08, 4.79659358e+08, 4.39623497e+08, 3.94639627e+08,\n",
       "        3.64480569e+08, 3.50057242e+08, 3.30069289e+08, 3.08890827e+08],\n",
       "       [4.37318591e+08, 4.07728562e+08, 3.84062685e+08, 3.56686930e+08,\n",
       "        3.37815474e+08, 3.28089843e+08, 3.14600808e+08, 3.01442130e+08]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cum_turb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zigzag_flat(input8x8):\n",
    "    assert input8x8.shape == (8,8)\n",
    "    zigzag = np.array((        [[0,   1,   5,  6,   14,  15,  27,  28],\n",
    "    [2,   4,   7,  13,  16,  26,  29,  42],\n",
    "    [3,   8,  12,  17,  25,  30,  41,  43],\n",
    "    [9,   11, 18,  24,  31,  40,  44,  53],\n",
    "    [10,  19, 23,  32,  39,  45,  52,  54],\n",
    "    [20,  22, 33,  38,  46,  51,  55,  60],\n",
    "    [21,  34, 37,  47,  50,  56,  59,  61],\n",
    "    [35,  36, 48,  49,  57,  58,  62,  63]]))\n",
    "    output64 = np.zeros(64)\n",
    "    for i in range(64):\n",
    "        for j in range(8):\n",
    "            for k in range(8):\n",
    "                if zigzag[j,k] == i:\n",
    "                    output64[i] = input8x8[j,k]\n",
    "    return output64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.58489075e+09, 1.10609953e+09, 1.13166132e+09, 9.80189560e+08,\n",
       "       9.72885545e+08, 9.55979093e+08, 7.87738279e+08, 8.56975178e+08,\n",
       "       8.72715544e+08, 8.17493728e+08, 6.59811478e+08, 7.42801160e+08,\n",
       "       7.70449479e+08, 7.17166788e+08, 6.54474643e+08, 6.07578847e+08,\n",
       "       6.01022010e+08, 6.46776977e+08, 6.56981810e+08, 6.14297205e+08,\n",
       "       5.78814667e+08, 5.18017447e+08, 5.43329292e+08, 5.47841972e+08,\n",
       "       5.51158415e+08, 5.47900180e+08, 5.55717840e+08, 5.18174214e+08,\n",
       "       4.06497216e+08, 4.73239469e+08, 5.08917178e+08, 4.77151132e+08,\n",
       "       4.70519627e+08, 4.89483029e+08, 4.79659358e+08, 4.37318591e+08,\n",
       "       4.07728562e+08, 4.39623497e+08, 4.30282225e+08, 4.18888762e+08,\n",
       "       4.50386912e+08, 4.39761886e+08, 3.77744007e+08, 3.60948821e+08,\n",
       "       3.99251676e+08, 3.98790572e+08, 3.89501514e+08, 3.94639627e+08,\n",
       "       3.84062685e+08, 3.56686930e+08, 3.64480569e+08, 3.70492958e+08,\n",
       "       3.64427124e+08, 3.41682253e+08, 3.25322782e+08, 3.44795328e+08,\n",
       "       3.50057242e+08, 3.37815474e+08, 3.28089843e+08, 3.30069289e+08,\n",
       "       3.16170288e+08, 3.08890827e+08, 3.14600808e+08, 3.01442130e+08])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zigzag_flat(cum_turb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
